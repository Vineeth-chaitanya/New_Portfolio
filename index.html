<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Vineeth Adapa | Data Scientist</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <!-- Hero section with ID -->
  <header id="hero">
    <h1>Vineeth Adapa</h1>
    <p><span class="accent">Data Scientist | ML Engineer</span></p>
  </header>

  <main>
    <section id="about">
      <p style="max-width: 600px;">I'm a data scientist who enjoys turning ideas into tools people actually rely on. Most of 
        my work sits at the overlap of Machine Learning, Statistics and Large Language Models. I enjoy
        taking messy, real world data and turning it into systems that help people make better decisions.
      </p>
      <p style="max-width: 600px;">
        Currently, At <span class="accent">Pan American Health Organization</span> I am spending most of my time working on Large Language Models to help 
        build recommendation systems. I try to be a perfectionist even with my data, thoughtful engineering, meaningful
        evaluation, and experiments that tell you something real.
      </p>
      <p style="max-width: 600px;">
        Before fully moving into data science, I worked as a programmer analyst, which taught me how
        data flows through Organizations and why clarity and reliability matter just as much as accuracy.
        That background paired with my master's degree in information sciences still shapes how I work today.
        I write readable code, ask practical questions, and try to build systems others can understand and maintain.
      </p>
      <p style="max-width: 600px;">
        Most days, I'm running, playing cricket or finding some excuse to get a workout in. Staying still 
        has never been my strong suit. 
      </p>
    </section>

    <section id="experience">
      <h2>Experience</h2>
      <div class="experience-item">
        <div class="date">Sep 2025 â€” Present</div>
        <h3>
          <a href="https://www.paho.org/en" target="_blank">Data Scientist Â· Pan American Health Organization</a>
        </h3>
        <p style="max-width: 620px;">At PAHO, I work across multilingual datasets and LLM-powered workflows to strengthen
          the journal's bibliometric and editorial intelligence. I design and operate LLM-powered
          NLP systems using models like Llama4:Scout and OpenAI text embedding models to classify
          research domains and generate article-similarity recommendations.
        </p>
        <p style="max-width: 620px;">
          A big part of my work is making these systems stable at scale token-aware batching,
          JSON repair, adaptive rate-limit handling and collaborating with editorial and bibliometric
          teams to unify datasets and support impact-factor initiatives.
        </p>
        <ul class="tech-list">
          <li>R programming</li>
          <li>Large-Language Models</li>
          <li>OpenAI text-embedding-3-large</li>
          <li>A/B testing</li>
        </ul>
      </div>

      <div class="experience-item">
        <div class="date">Feb 2025 â€” Sep 2025</div>
        <h3>
          <a href="https://thrivingelements.org/" target="_blank">Data Scientist Â· Thriving Elements</a>
        </h3>
        <p style="max-width: 620px;">At Thriving Elements, I built a mentor-mentee recommendation system that automated matching across
          cohorts. I combined TF-IDF, cosine similarity, and sentence-BERT embeddings with FAISS search to
          improve semantic relevance and reduce manual matching effort. I engineered structured features
          from participant profiles using Python and SQL.
        </p>
        <p style="max-width: 620px;">
          I worked closely with program managers to refine matching criteria, integrate feedback loops,
          and align the system with how the Organization actually operates.
        </p>
        <ul class="tech-list">
          <li>Python</li>
          <li>SQL</li>
          <li>FAISS</li>
          <li>sentence-BERT</li>
          <li>TF-IDF</li>
        </ul>
      </div>

      <div class="experience-item">
        <div class="date">Feb 2021 â€” Dec 2022</div>
        <h3>
          <a href="https://www.cognizant.com/us/en" target="_blank">Programmer Analyst Â· Cognizant Technology Solutions</a>
        </h3>
        <p style="max-width: 620px;">At Cognizant, I supported data ingestion, transformation, and validation workflows across
          SQL Server and Excel for financial services client. I optimized SQL queries, stored procedures,
          and reporting scripts to improve turnaround time and reliability. I also built Power BI
          dashboards that visualized KPIs and operational metrics, helping stakeholders make informed decisions.
        </p>
        <p style="max-width: 620px;">
          A lot of my work involved data-quality audits, root-cause analysis, and collaborating with
          cross-functional teams in Agile sprints to test and deploy analytics solutions into production.
        </p>
        <ul class="tech-list">
          <li>SQL Server</li>
          <li>Python</li>
          <li>Excel</li>
          <li>ETL workflows</li>
          <li>Power BI</li>
        </ul>
      </div>
    </section>

    <section id="projects">
      <h2>Projects</h2>
      <div class="project-grid">
        <div class="project-card">
            <a href="https://github.com/Vineeth-chaitanya/USBondYield_Prediction" target="_blank" class="project-link">
                <span class="link-icon">ðŸ”—</span>
            </a>
            <h3>US Bond Yield Forecasting</h3>
            <p style="max-width: 620px;">I developed a forecasting system for US 10-year Treasury bond yields using macroeconomic indicators.
                The project compared ARIMAX, LSTMs, and attention-based neural networks to capture long-term trends
                and improve predictive accuracy. It highlights my ability to blend statistical modeling with modern deep 
                learning for financial time-series analysis.
            </p>
            <ul class="tech-list">
                <li>Python</li>
                <li>Pandas</li>
                <li>scikit-learn</li>
                <li>ARIMAX</li>
                <li>LSTM</li>
            </ul>
        </div>
        
        <div class="project-card">
            <a href="https://github.com/Vineeth-chaitanya/AQI-Prediction" target="_blank" class="project-link">
                <span class="link-icon">ðŸ”—</span>
            </a>
            <h3>AQI Prediction</h3>
            <p style="max-width: 620px;">
                I built a machine learning pipeline to predict Air Quality Index(AQI) levels using meterological
                and pollutant data. The project involved cleaning and engineering features from raw environmental
                datasets, then experimenting with regression models and ensemble methods to forecast AQI with higher accuracy.
                I emphasized evaluation metrics like RMSE and RÂ² to validate performance, and visualized predictions
                against actual AQI trends to ensure the system provided actionable insights.
            </p>
            <ul class="tech-list">
                <li>R</li>
                <li>XGBoost</li>
                <li>Random Forest</li>
                <li>shiny</li>
            </ul>

        </div>
        <div class="project-card">
            <a href="https://github.com/Vineeth-chaitanya/Resume_analyser" target="_blank" class="project-link">
                <span class="link-icon">ðŸ”—</span>
            </a>
            <h3>Resume Analyzer</h3>
            <p style="max-width: 620px;">
                I built a resume parsing system that processes unstructured text from resumes and converts it into structured, recruiterâ€‘friendly data. 
                Using spaCy NLP pipelines, the system extracts key fields such as skills, education, and work experience, then standardizes them into consistent formats for easier screening. 
                The project was tested on over 2,500 resumes, demonstrating its ability to automate manual review and reduce recruiter workload. Beyond extraction, 
                I focused on clean data engineering and validation, ensuring outputs were reliable enough to integrate into downstream HR workflows
            </p>
            <ul class="tech-list">
                <li>Python</li>
                <li>spaCy</li>
                <li>Regex</li>
                <li>NLP</li>
            </ul>

        </div>
      </div>
    </section>
  </main>

<aside class="social-sidebar horizontal">
  <div class="sidebar-line"></div> <!-- Thin line above icons -->
  <ul>
    <li>
      <a href="https://github.com/yourusername" target="_blank" aria-label="GitHub">
        <img src="github.svg" alt="GitHub">
      </a>
    </li>
    <li>
      <a href="https://linkedin.com/in/yourname" target="_blank" aria-label="LinkedIn">
        <img src="linkedin.svg" alt="LinkedIn">
      </a>
    </li>
    <li>
      <a href="mailto:your.email@gmail.com" aria-label="Email">
        <img src="email.svg" alt="Email">
      </a>
    </li>
  </ul>
</aside>

<footer id="contact">  
  <p class="footer-credit">Â© 2025 Vineeth Adapa</p>
</footer>


  <!-- JavaScript at the end of body -->
  <script src="script.js"></script>
</body>
</html>